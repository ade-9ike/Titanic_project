{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Load libraries into code environment\n\nimport numpy as np\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load test and train datasets into code environment\n\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\n\n#Preview and get insights into the dataset\ntest.info()\ntrain.info()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cleaning the train dataset\n#Fill missing values in Age column of train dataset with mean of the column\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='mean')\n\nage_column_train = train[['Age']]\n\n\nimputer.fit(age_column_train)\n\n\ntrain['Age'] = imputer.transform(age_column_train)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop the columns that are less significant\n\ntrain_rev = train.drop(['Name', 'Cabin', 'Ticket'], axis=1)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert column with ordinal data to numeric data using Label Encoder\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ntrain_rev['Pclass'] = le.fit_transform(train_rev['Pclass'])\n\n\n#Convert columns with categorical data to numeric data using Label Encoder\ntrain_rev = pd.get_dummies(train_rev, columns=['Sex', 'Embarked'])\n\n\ntrain_rev.info()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check relationship between features and and target variable using correlation analysis\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ntarget_variable = 'Survived'\ncorrelation_matrix = train_rev.corr()\ntarget_correlations = correlation_matrix[target_variable]\n\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='cividis', fmt=\".2f\")\nplt.title(f'Correlation Heatmap (Target Variable: {target_variable})')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop features with the lowest correlation to the target variable\n\ntrain_rev = train_rev.drop(['Parch','Embarked_C', 'Embarked_Q', 'Embarked_S'], axis=1)\n\ntrain_rev.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import the necessary sklearn libraries\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_validate\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n\nX = train_rev.drop(\"Survived\", axis=1)\ny = train_rev[['Survived']]\n\n#Split the train dataset\nX_train, X_test ,y_train ,y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n#Initializing models\nmodels = [\n    (\"Logistic Regression\", LogisticRegression()),\n    (\"Random Forest\", RandomForestClassifier()),\n    (\"Decision Tree\", DecisionTreeClassifier())\n        ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train the models and check metrics score\n\n#Metric 1 - Accuracy\n\nfor model_name,model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    print(f\"{model_name} Accuracy: {accuracy}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Metric 2 - Precision\n\nfor model_name,model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    precision = precision_score(y_test, y_pred)\n    \n    print(f\"{model_name} Precision: {precision}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Metric 3 - Recall\n\nfor model_name,model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    recall = recall_score(y_test, y_pred)\n    \n    print(f\"{model_name} Recall: {recall}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model_name,model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    cm = confusion_matrix(y_test, y_pred)\n    \n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(f\"Confusion Matrix for {model_name}\")\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scoring = ['accuracy', 'precision', 'recall']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform cross-validation and evaluate models\nfor model_name, model in models:\n    # Perform cross-validation (5-fold in this example)\n    cv_results = cross_validate(model, X_train, y_train, cv=5, scoring= scoring)\n    \n    # Fit the model on the full training data\n    model.fit(X_train, y_train)\n    \n    # Make predictions on the test data\n    y_pred = model.predict(X_test)\n    \n    # Calculate evaluation metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    \n    for metric in scoring:\n        scores = cv_results[f\"test_{metric}\"]\n        print(f\"{model_name} - {metric.capitalize()} Scores: {scores}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check the test dataset\n\n#Fill missing data in Age column with mean\nage_column_test = test[['Age']]\nimputer.fit(age_column_test)\ntest['Age'] = imputer.transform(age_column_test)\n\n#Drop columns that were dropped in train dataset\ntest = test.drop(['Name', 'Cabin', 'Ticket', 'Embarked', 'Parch'], axis=1)\n\n#Transform ordinal data to numeric data\ntest['Pclass'] = le.fit_transform(test['Pclass'])\n#Convert columns with categorical data to numeric data using Label Encoder\ntest = pd.get_dummies(test, columns=['Sex']) \n\n\n#Fill the missing data in the fare column with the most frequent data\n\nimputer2 = SimpleImputer(strategy='most_frequent')\nfare_column_test = test[['Fare']]\nimputer2.fit(fare_column_test)\ntest['Fare'] = imputer2.transform(fare_column_test)\n\ntest.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model_name, model in models:\n    if model_name == \"Random Forest\":\n        random_forest_model = model\n        \n        y_train = y_train.values.ravel()\n        \n        random_forest_model.fit(X_train, y_train)\n        \n        predictions = random_forest_model.predict(test)\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': predictions})\n\npredictions\n\npredictions.to_csv('submissions.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# To download the file in Jupyter Notebook\n\nfrom IPython.display import FileLink\nFileLink('submissions.csv')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}